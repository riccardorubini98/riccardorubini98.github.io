<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Deep Learning | Riccardo Rubini</title><link>https://riccardorubini98.github.io/tag/deep-learning/</link><atom:link href="https://riccardorubini98.github.io/tag/deep-learning/index.xml" rel="self" type="application/rss+xml"/><description>Deep Learning</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 01 May 2023 00:00:00 +0000</lastBuildDate><image><url>https://riccardorubini98.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url><title>Deep Learning</title><link>https://riccardorubini98.github.io/tag/deep-learning/</link></image><item><title>MSc Thesis - PROMET</title><link>https://riccardorubini98.github.io/project/promet/</link><pubDate>Mon, 01 May 2023 00:00:00 +0000</pubDate><guid>https://riccardorubini98.github.io/project/promet/</guid><description>&lt;p>In my thesis, I focused on addressing the Fine-grained Entity Typing task (FET), specifically in few-shot scenario, where only a limited amount of annotated data is available for training. In recent years, there has been a significant advancement in using prompt-based approaches for FET, leveraging Pre-trained Language Models (PLMs) MLM capabilities. These approaches, particularly in few-shot scenarios, have demonstrated superior performance by transforming the entity classification task into a &lt;em>cloze&lt;/em>-style task based on masked tokens.&lt;/p>
&lt;p>However, these existing methods have encountered challenges, primarily related to the requirement of defining specific keywords for each label in the classification set. In my research, I introduced a novel approach called PROMET (PROmpt-tuning using implicit Mask filling for Entity Typing) to overcome these issues. PROMET utilizes the information extracted from the &lt;em>cloze&lt;/em>-style task by directly leveraging the masked token embeddings, eliminating the need to pass through the masked language modeling head of the PLM. This innovation enables PROMET to operate without the keyword search and reduces its parameter count significantly, making it more efficient compared to other prompt-based methods.&lt;/p>
&lt;p>Furthermore, I developed two distinct implementation modes for PROMET: one referred to as &lt;em>flat&lt;/em>, which consists of a single model, and another called &lt;em>stack&lt;/em>, involving a hierarchical system of classifiers. The stack mode takes into account the inherent hierarchy among labels in the classification set.&lt;/p>
&lt;p>Benchmark results from my research demonstrated that PROMET in the flat mode achieves performance that aligns with the current state of the art, despite its simplicity compared to other approaches. PROMET in flat mode outperforms the stack mode. However, the latter is characterized by greater flexibility and modularity, aspects that make it preferable in the ontology specialization scenario.&lt;/p>
&lt;p>In summary, my thesis project introduced PROMET, a novel prompt-based approach for the Fine-grained Entity Typing task, which addresses the challenges of few-shot learning while maintaining competitive performance and offering flexibility through different implementation modes.&lt;/p>
&lt;p>Full Thesis can be accessed at this &lt;a href="https://drive.google.com/file/d/1vL1OhKphkRIpsDQQDmomHL6mC9CExk-W/view?usp=sharing" target="_blank" rel="noopener">link&lt;/a>&lt;/p></description></item><item><title>Image Classification</title><link>https://riccardorubini98.github.io/project/computer-vision/</link><pubDate>Tue, 01 Mar 2022 00:00:00 +0000</pubDate><guid>https://riccardorubini98.github.io/project/computer-vision/</guid><description>&lt;p>In this computer vision project, our goal was to classify architectural heritage images. We had a dataset of 10,235 training images, each sized at 128x128 pixels, and these images fell into 10 different architectural categories.&lt;/p>
&lt;p>To build our model, we followed a gradual approach. We began with simple, shallow neural networks and progressively deepened them as we advanced in the model development process. This allowed us to create more complex models over time.&lt;/p>
&lt;p>To ensure that our model wouldn&amp;rsquo;t memorize the training data but instead generalize well to new, unseen images, we employed various techniques for regularization. These techniques helped us strike a balance between model complexity and generalization ability.&lt;/p>
&lt;p>One of the key strategies we implemented was &lt;strong>data augmentation&lt;/strong>. With this technique, we expanded our training dataset by applying transformations to the existing images. Specifically, we used horizontal flipping and random zoom, effectively tripling our training data. This helped our model learn better from a wider variety of examples.&lt;/p>
&lt;p>Our model &lt;strong>could correctly classify approximately 8 out of 10 test images&lt;/strong>. This demonstrated its capability to accurately identify architectural elements in the images.&lt;/p>
&lt;p>Additionally, we assessed our model&amp;rsquo;s performance using the F1 score, which combines precision and recall. 9 out of the 10 architectural categories achieved a good F1 score, surpassing the 0.70 threshold. This indicated that our model excelled in most of categories.&lt;/p>
&lt;p>This project was developed on Python via the &lt;em>Keras&lt;/em> library.&lt;/p></description></item></channel></rss>