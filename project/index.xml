<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Projects | Riccardo Rubini</title><link>https://riccardorubini98.github.io/project/</link><atom:link href="https://riccardorubini98.github.io/project/index.xml" rel="self" type="application/rss+xml"/><description>Projects</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 01 May 2023 00:00:00 +0000</lastBuildDate><image><url>https://riccardorubini98.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url><title>Projects</title><link>https://riccardorubini98.github.io/project/</link></image><item><title>MSc Thesis - PROMET</title><link>https://riccardorubini98.github.io/project/promet/</link><pubDate>Mon, 01 May 2023 00:00:00 +0000</pubDate><guid>https://riccardorubini98.github.io/project/promet/</guid><description>&lt;p>In my thesis, I focused on addressing the Fine-grained Entity Typing task (FET), specifically in few-shot scenario, where only a limited amount of annotated data is available for training. In recent years, there has been a significant advancement in using prompt-based approaches for FET, leveraging Pre-trained Language Models (PLMs) MLM capabilities. These approaches, particularly in few-shot scenarios, have demonstrated superior performance by transforming the entity classification task into a &lt;em>cloze&lt;/em>-style task based on masked tokens.&lt;/p>
&lt;p>However, these existing methods have encountered challenges, primarily related to the requirement of defining specific keywords for each label in the classification set. In my research, I introduced a novel approach called PROMET (PROmpt-tuning using implicit Mask filling for Entity Typing) to overcome these issues. PROMET utilizes the information extracted from the &lt;em>cloze&lt;/em>-style task by directly leveraging the masked token embeddings, eliminating the need to pass through the masked language modeling head of the PLM. This innovation enables PROMET to operate without the keyword search and reduces its parameter count significantly, making it more efficient compared to other prompt-based methods.&lt;/p>
&lt;p>Furthermore, I developed two distinct implementation modes for PROMET: one referred to as &lt;em>flat&lt;/em>, which consists of a single model, and another called &lt;em>stack&lt;/em>, involving a hierarchical system of classifiers. The stack mode takes into account the inherent hierarchy among labels in the classification set.&lt;/p>
&lt;p>Benchmark results from my research demonstrated that PROMET in the flat mode achieves performance that aligns with the current state of the art, despite its simplicity compared to other approaches. PROMET in flat mode outperforms the stack mode. However, the latter is characterized by greater flexibility and modularity, aspects that make it preferable in the ontology specialization scenario.&lt;/p>
&lt;p>In summary, my thesis project introduced PROMET, a novel prompt-based approach for the Fine-grained Entity Typing task, which addresses the challenges of few-shot learning while maintaining competitive performance and offering flexibility through different implementation modes.&lt;/p>
&lt;p>Full Thesis can be accessed at this &lt;a href="https://drive.google.com/file/d/1vL1OhKphkRIpsDQQDmomHL6mC9CExk-W/view?usp=sharing" target="_blank" rel="noopener">link&lt;/a>&lt;/p></description></item><item><title>L'Italia Solitaria</title><link>https://riccardorubini98.github.io/project/italiasolitaria/</link><pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate><guid>https://riccardorubini98.github.io/project/italiasolitaria/</guid><description>&lt;p>This infographic was crafted as a contribution to the &lt;em>&amp;ldquo;Data (in) context - Thinking with Data&amp;rdquo;&lt;/em> competition. This competition was organized by &lt;em>ISTAT&lt;/em>, &lt;em>SocietÃ  Statistica Italiana&lt;/em> (SIS), and the &lt;em>University of Salerno&lt;/em>, with the sponsorship of &lt;em>Banca Campania Centro&lt;/em>.&lt;/p>
&lt;p>The poster focuses on the issue of loneliness in Italy, examining this phenomenon across different age groups, genders, and geographical regions. To create this infographic, original data from ISTAT was carefully processed to make it suitable for data visualization. The visual elements were generated using R and the &lt;em>ggplot2&lt;/em> package, and later refined, enriched, and standardized in Illustrator.&lt;/p>
&lt;p>This poster received the top prize in the &lt;em>&amp;ldquo;Best Poster for Communicative Effectiveness&amp;rdquo;&lt;/em> category.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="INFOGRAFICA" srcset="
/project/italiasolitaria/image_hu54d91a2bab3bb3210b563591de8feb7d_1735761_7b8c77c4f37322366f6d38958e32a0c0.webp 400w,
/project/italiasolitaria/image_hu54d91a2bab3bb3210b563591de8feb7d_1735761_bb11c1d0b38aad225b60682940aaf318.webp 760w,
/project/italiasolitaria/image_hu54d91a2bab3bb3210b563591de8feb7d_1735761_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://riccardorubini98.github.io/project/italiasolitaria/image_hu54d91a2bab3bb3210b563591de8feb7d_1735761_7b8c77c4f37322366f6d38958e32a0c0.webp"
width="537"
height="760"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p></description></item><item><title>Image Classification</title><link>https://riccardorubini98.github.io/project/computer-vision/</link><pubDate>Tue, 01 Mar 2022 00:00:00 +0000</pubDate><guid>https://riccardorubini98.github.io/project/computer-vision/</guid><description>&lt;p>In this computer vision project, our goal was to classify architectural heritage images. We had a dataset of 10,235 training images, each sized at 128x128 pixels, and these images fell into 10 different architectural categories.&lt;/p>
&lt;p>To build our model, we followed a gradual approach. We began with simple, shallow neural networks and progressively deepened them as we advanced in the model development process. This allowed us to create more complex models over time.&lt;/p>
&lt;p>To ensure that our model wouldn&amp;rsquo;t memorize the training data but instead generalize well to new, unseen images, we employed various techniques for regularization. These techniques helped us strike a balance between model complexity and generalization ability.&lt;/p>
&lt;p>One of the key strategies we implemented was &lt;strong>data augmentation&lt;/strong>. With this technique, we expanded our training dataset by applying transformations to the existing images. Specifically, we used horizontal flipping and random zoom, effectively tripling our training data. This helped our model learn better from a wider variety of examples.&lt;/p>
&lt;p>Our model &lt;strong>could correctly classify approximately 8 out of 10 test images&lt;/strong>. This demonstrated its capability to accurately identify architectural elements in the images.&lt;/p>
&lt;p>Additionally, we assessed our model&amp;rsquo;s performance using the F1 score, which combines precision and recall. 9 out of the 10 architectural categories achieved a good F1 score, surpassing the 0.70 threshold. This indicated that our model excelled in most of categories.&lt;/p>
&lt;p>This project was developed on Python via the &lt;em>Keras&lt;/em> library.&lt;/p></description></item><item><title>Reviews analysis and processing</title><link>https://riccardorubini98.github.io/project/amazon-book-review/</link><pubDate>Tue, 01 Feb 2022 00:00:00 +0000</pubDate><guid>https://riccardorubini98.github.io/project/amazon-book-review/</guid><description>&lt;p>In this project, we conducted two common tasks in text mining using a large collection of e-book reviews from Amazon.com. Our main objectives were as follows:&lt;/p>
&lt;p>&lt;strong>Text Classification for Sentiment Analysis:&lt;/strong> Our first goal was to automatically determine the sentiment expressed in the reviews, whether they were positive or negative. To accomplish this, we employed a supervised technique known as Text Classification. After experimenting with various methods, we found that the lasso logistic classifier provided the most satisfactory results. It achieved a recall rate of 92% for positive reviews and 90% for negative reviews. In simpler terms, this means that our model was able to accurately identify whether a review was positive or negative in the majority of cases.&lt;/p>
&lt;p>&lt;strong>Topic Modeling:&lt;/strong> The second objective of our project was to uncover the main topics discussed in the e-book reviews. We used an unsupervised technique called Topic Modeling for this purpose. Imagine it as a method to identify the key themes or subjects that frequently came up in the reviews. After trying different approaches, we discovered that the algebraic Non-negative Matrix Factorization (NMF) technique was the most effective in identifying reliable topics. These topics were related to various aspects, such as different shades of opinions and various categories of books that were being reviewed.&lt;/p>
&lt;p>In summary, our project involved analyzing a large number of e-book reviews from Amazon.com. We used machine learning techniques to determine whether the reviews were positive or negative (sentiment analysis) and to identify the main topics that emerged from these reviews (topic modeling). The results of our efforts showed that our models were quite accurate in sentiment analysis, and we were able to extract meaningful topics from the reviews using advanced mathematical techniques like NMF.&lt;/p></description></item><item><title>Fantaoracolo</title><link>https://riccardorubini98.github.io/project/fantaoracolo/</link><pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate><guid>https://riccardorubini98.github.io/project/fantaoracolo/</guid><description>&lt;p>&lt;a href="https://fantaoracolo-ux9tn8qkjepeujnqdb3xeg.streamlit.app/" target="_blank" rel="noopener">FANTAORACOLO&lt;/a> is a web application designed to help fantasy football enthusiasts make informed decisions about which players to include in their fantasy teams. It achieves this by analyzing real data and using statistical techniques to recommend the best player choices for your fantasy football lineup, increasing your chances of winning your next match.&lt;/p>
&lt;p>Here are the key components of the project:&lt;/p>
&lt;p>&lt;strong>Working Demo Web App:&lt;/strong> The project involves creating a functional web application (demo at this &lt;a href="https://share.streamlit.io/riccardorubini98/fantaoracolo/main/app.py" target="_blank" rel="noopener">LINK&lt;/a>) where users can access the FANTAORACOLO service. This web app will provide an easy and user-friendly interface for users to input their fantasy football team details and receive personalized player recommendations.&lt;/p>
&lt;p>&lt;strong>Web Scraping:&lt;/strong> To provide accurate and up-to-date recommendations, FANTAORACOLO performs web scraping. This means it collects football and fantasy football data from various online sources. This data includes player statistics, team performance, and other relevant information necessary to make informed suggestions.&lt;/p>
&lt;p>&lt;strong>Business Model Canvas:&lt;/strong> The project also includes the development of a business model canvas. This canvas outlines the startup&amp;rsquo;s strategy and plans for the web app. It covers aspects such as target audience, revenue streams, key partners, and channels for reaching users. This canvas serves as a roadmap for the project&amp;rsquo;s growth and sustainability.&lt;/p></description></item><item><title>Time series analysis</title><link>https://riccardorubini98.github.io/project/timeseries/</link><pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate><guid>https://riccardorubini98.github.io/project/timeseries/</guid><description>&lt;p>In this project, we conducted an analysis and forecasting of carbon monoxide (CO) emissions using a combination of statistical and deep learning techniques. We explored various modeling approaches, including AutoRegressive Integrated Moving Average (ARIMA) models, Unobserved Components Model (UCM), and Long Short-Term Memory (LSTM) deep neural networks, to select the most suitable model. Our final selected model achieved a Mean Absolute Percentage Error (MAPE) of 12%, demonstrating its accuracy in predicting CO emissions&lt;/p></description></item><item><title>Digital Marketing</title><link>https://riccardorubini98.github.io/project/webmarketing/</link><pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate><guid>https://riccardorubini98.github.io/project/webmarketing/</guid><description>&lt;p>The primary goal of this project is to better understand and manage customer churn (when customers stop using our services) and to explore the potential impact of mail marketing in reducing churn rates.&lt;/p>
&lt;p>Project Components:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>Anti-Churn Model:&lt;/strong>
We will build a specialized model known as an &amp;ldquo;anti-churn model.&amp;rdquo; This model helps us predict the likelihood of each customer leaving our company&amp;rsquo;s services. By analyzing various factors, such as customer behavior and engagement, we can estimate the probability that a customer might stop using our products or services.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>RFM Segmentation:&lt;/strong>
In addition to the anti-churn model, we will use a technique called &amp;ldquo;RFM segmentation.&amp;rdquo; RFM stands for Recency, Frequency, and Monetary value. This segmentation method helps us identify our most valuable customers based on how recently they made a purchase, how often they do so, and how much money they spend. Understanding these high-value customers is crucial for targeted marketing efforts.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Mail Marketing Analysis:&lt;/strong>
We will also investigate the effectiveness of mail marketing campaigns in reducing customer churn rates. This involves sending promotional materials or offers to customers via physical mail. We will analyze whether these mail marketing efforts have a positive impact on retaining customers and if they can help decrease churn.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>Project Benefits:&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Improved Customer Retention:&lt;/strong> By identifying customers at risk of leaving and high-value customers, we can implement strategies to keep valuable clients and reduce churn. Our strategy provides a 20% increase in performance over the classical approach
&lt;strong>Cost-Efficient Marketing:&lt;/strong> The analysis of mail marketing effectiveness will help us determine whether this traditional marketing approach is worth the investment in retaining customers.
&lt;strong>Data-Driven Decisions:&lt;/strong> The project will rely on data analysis to make informed decisions, ensuring our marketing efforts are targeted and efficient.&lt;/p></description></item><item><title>Wikitrend</title><link>https://riccardorubini98.github.io/project/wikitrend/</link><pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate><guid>https://riccardorubini98.github.io/project/wikitrend/</guid><description>&lt;p>In this data management and data visualization project, our analysis involves three key components:&lt;/p>
&lt;p>&lt;strong>Managing Data with MongoDB Document Database:&lt;/strong> To efficiently handle and store data, we utilized MongoDB, a robust document database. This allowed us to organize and manage our dataset effectively, ensuring it is easily accessible and scalable.&lt;/p>
&lt;p>&lt;strong>Categorization of Wikipedia Pages&lt;/strong>: Our project involved the categorization of Wikipedia pages with a system that, among other things, uses a third parts algorithm. This system was designed to query a Knowledge Base (KB), specifically Wikidata, and leverage various online tools accessible via APIs. Through this process, we were able to categorize Wikipedia pages accurately and efficiently, enhancing data organization and accessibility.&lt;/p>
&lt;p>&lt;strong>Construction of Interactive Infographics with Tableau:&lt;/strong> To make the categorized data more accessible and insightful, we constructed interactive infographics using Tableau. These infographics provided users with a dynamic and visually engaging way to explore and interact with the categorized data.&lt;/p>
&lt;p>&lt;strong>Evaluation Using Questionnaires and User Tests:&lt;/strong> To ensure the effectiveness of our data visualization solution, we conducted rigorous evaluations. This included gathering feedback through questionnaires from users who interacted with our Tableau-based infographics. Additionally, we conducted user tests to assess the usability and user-friendliness of our visualization tools. This feedback helped us refine our design and ensure that the final product met the needs and expectations of our target audience.&lt;/p>
&lt;p>The full report is published &lt;a href="https://riccardorubini98.github.io/wikitrend_site/" target="_blank" rel="noopener">HERE&lt;/a>&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="DATA VIZ 1" srcset="
/project/wikitrend/data_viz_1_huf7624efadd5975e23832b29f24359357_164122_4a4b8792e3ea0faaf5c3827239809b02.webp 400w,
/project/wikitrend/data_viz_1_huf7624efadd5975e23832b29f24359357_164122_2e8daea6b46f639e278175a362a505c3.webp 760w,
/project/wikitrend/data_viz_1_huf7624efadd5975e23832b29f24359357_164122_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://riccardorubini98.github.io/project/wikitrend/data_viz_1_huf7624efadd5975e23832b29f24359357_164122_4a4b8792e3ea0faaf5c3827239809b02.webp"
width="760"
height="428"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="DATA VIZ 2" srcset="
/project/wikitrend/data_viz_2_hub183868395e210235cde56d10f33f7b5_195528_0e732701be91647a7af3e0c802238c2d.webp 400w,
/project/wikitrend/data_viz_2_hub183868395e210235cde56d10f33f7b5_195528_31d2156f21f2da7e0baf90f0243d5c48.webp 760w,
/project/wikitrend/data_viz_2_hub183868395e210235cde56d10f33f7b5_195528_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://riccardorubini98.github.io/project/wikitrend/data_viz_2_hub183868395e210235cde56d10f33f7b5_195528_0e732701be91647a7af3e0c802238c2d.webp"
width="760"
height="428"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p></description></item></channel></rss>